numericInput(inputId = "btcmo",label = NULL,value = 10,min=1,max=10000,step = 1,width = "100px")
),
box(title = "Interaction Depth",width = 2,solidHeader = TRUE,status = "warning",
numericInput(inputId = "btcid",label = NULL,value = 1,min=1,max=15000,step = 1,width ="100px")
),
box(title = "Shrinkage",width = 2,solidHeader = TRUE,status = "warning",
numericInput(inputId = "btcsg",label = NULL,value = 0.05,min=0,max=1,step = 0.01,width ="100px")
),
box(title = "Distribution",width = 2,solidHeader = TRUE,status = "warning",
selectInput("btcdu", label = NULL,  choices = list("bernoulli","multinomial","gaussian", "laplace","adaboost", "tdist","huberized",
"poisson","coxph","quantile","pairwise"),selected = "bernoulli")
)
)
}
else if (input$pselmd =="SVM_Classifier"){
fluidRow(
box(title = "Cost of Violations",width = 2,solidHeader = TRUE,status = "warning",
numericInput(inputId = "svccs",label = NULL,value = 0.1,min=0,max=10000,step = 0.1,width = "100px")
),
box(title = "Polynomial Kernel Degree",width = 2,solidHeader = TRUE,status = "warning",
numericInput(inputId = "svcpl",label = NULL,value = 2,min=1,max=10000,step = 1,width = "100px")
),
box(title = "Gamma Value",width = 2,solidHeader = TRUE,status = "warning",
numericInput(inputId = "svcgm",label = NULL,value = 0.1,min=0,max=15000,step = 0.05,width ="100px")
),
box(title = "Kernel Type",width = 2,solidHeader = TRUE,status = "warning",
selectInput("svckt", label = NULL,  choices = list("linear","poly","radial"),selected = "linear")
)
)
}
else if (input$pselmd =="Naive_Bayes"){
fluidRow(
box(title = "Laplace smoothing",width = 2,solidHeader = TRUE,status = "warning",
numericInput(inputId = "nbls",label = NULL,value = 0.1,min=0,max=10000,step = 0.1,width = "100px")
)
)
}
else if (input$pselmd =="Linear_Regression"){
fluidRow(
box(title = "No parameters to select in Linear Regression Just Click RUN button!",width = 12,solidHeader = TRUE,status = "primary"
)
)
}
else if (input$pselmd =="Decision_Tree_Regressor"){
fluidRow(
box(title = "Max. Tree Depth",width = 2,solidHeader = TRUE,status = "warning",
numericInput(inputId = "trrnt",label = NULL,value = 5,min=1,max=10000,step = 1,width = "100px")
),
box(title = "Min. no obs to split",width = 2,solidHeader = TRUE,status = "warning",
numericInput(inputId = "trrms",label = NULL,value = 2,min=0,max=10000,step = 1,width = "100px")
),
box(title = "Min no. obs per bin",width = 2,solidHeader = TRUE,status = "warning",
numericInput(inputId = "trrmb",label = NULL,value = 1,min=1,max=15000,step = 1,width ="100px")
)
)
}
else if (input$pselmd =="Random_Forest_Regressor"){
fluidRow(
box(title = "No.of Tress",width = 2,solidHeader = TRUE,status = "warning",
numericInput(inputId = "rfrnt",label = NULL,value = 200,min=0,max=10000,step = 100,width = "100px")
),
box(title = "No. of Col vars to sample",width = 2,solidHeader = TRUE,status = "warning",
numericInput(inputId = "rfrmt",label = NULL,value = 2,min=0,max=10000,step = 1,width = "100px")
),
box(title = "Max no. of Nodes",width = 2,solidHeader = TRUE,status = "warning",
numericInput(inputId = "rfrmn",label = NULL,value = 32,min=1,max=15000,step = 1,width ="100px")
),
box(title = "Min size of Terminal Nodes",width = 2,solidHeader = TRUE,status = "warning",
numericInput(inputId = "rfrns",label = NULL,value = 1,min=1,max=30,step = 1,width ="100px")
)
)
}
else if (input$pselmd =="Boosting_GBM_Regressor"){
fluidRow(
box(title = "No.of Trees",width = 2,solidHeader = TRUE,status = "warning",
numericInput(inputId = "btrnt",label = NULL,value = 200,min=0,max=10000,step = 100,width = "100px")
),
box(title = "Min. obs in Node",width = 2,solidHeader = TRUE,status = "warning",
numericInput(inputId = "btrmo",label = NULL,value = 10,min=1,max=10000,step = 1,width = "100px")
),
box(title = "Interaction Depth",width = 2,solidHeader = TRUE,status = "warning",
numericInput(inputId = "btrid",label = NULL,value = 1,min=1,max=15000,step = 1,width ="100px")
),
box(title = "Shrinkage",width = 2,solidHeader = TRUE,status = "warning",
numericInput(inputId = "btrsg",label = NULL,value = 0.05,min=0,max=1,step = 0.01,width ="100px")
),
box(title = "Distribution",width = 2,solidHeader = TRUE,status = "warning",
selectInput("btrdu", label = NULL,  choices = list("bernoulli","multinomial","gaussian", "laplace","adaboost", "tdist","huberized",
"poisson","coxph","quantile","pairwise"),selected = "gaussian")
)
)
}
else if (input$pselmd =="SVM_Regressor"){
fluidRow(
box(title = "Cost of Violations",width = 2,solidHeader = TRUE,status = "warning",
numericInput(inputId = "svrcs",label = NULL,value = 0.1,min=0,max=10000,step = 0.1,width = "100px")
),
box(title = "Polynomial Kernel Degree",width = 2,solidHeader = TRUE,status = "warning",
numericInput(inputId = "svrpl",label = NULL,value = 2,min=1,max=10000,step = 1,width = "100px")
),
box(title = "Gamma Value",width = 2,solidHeader = TRUE,status = "warning",
numericInput(inputId = "svrgm",label = NULL,value = 0.1,min=0,max=15000,step = 0.05,width ="100px")
),
box(title = "Kernel Type",width = 2,solidHeader = TRUE,status = "warning",
selectInput("svrkt", label = NULL,  choices = list("linear","poly","radial"),selected = "linear")
)
)
}
})
STextinputC <- eventReactive(input$actionc, {
if (input$selectc =="Logistic_Regression"){
xvars = input$xvars
yvar = input$yvar
dset = data.frame(data())
dset[,yvar] = as.factor(dset[,yvar])
tdset = data.frame(tdata())
tdset[,yvar] = as.factor(tdset[,yvar])
frmla = paste(yvar,"~",paste(xvars,collapse = "+"))
glm_fit = glm(as.formula(frmla),family = "binomial",data = dset)
glm_probs = predict(glm_fit,data = dset,type = "response")
dset$glmprobs = glm_probs
tglm_probs = predict(glm_fit,newdata = tdset,type = "response")
threshold <- function(predict, response) {
r <- pROC::roc(response, predict)
r$thresholds[which.max(r$sensitivities + r$specificities)]
}
thrshld = threshold(dset$glmprobs,dset[,yvar])
dset$glm_pred = 0
dset$glm_pred[dset$glmprobs>thrshld]=1
tble = table(dset$glm_pred,dset[,yvar])
acc = (tble[1,1]+tble[2,2])/sum(tble)
tdset$glm_predt = 0
tdset$glm_predt[tglm_probs>thrshld]=1
tblet = table(tdset$glm_predt,tdset[,yvar])
acct = (tblet[1,1]+tblet[2,2])/sum(tblet)
print(paste("Logistic Regression Results"))
print(paste("Train accuracy",round(acc*100,2)))
print(paste("Test accuracy",round(acct*100,2)))
print(paste("Model summary"))
print(summary(glm_fit))
}
else if (input$selectc =="Random_Forest_Classifer"){
xvars = input$xvars
yvar = input$yvar
dset = data.frame(data())
dset[,yvar] = as.factor(dset[,yvar])
dsett = data.frame(tdata())
dsett[,yvar] = as.factor(dsett[,yvar])
frmla = paste(yvar,"~",paste(xvars,collapse = "+"))
for (i in 1:length(names(dset))){
if (typeof(dset[,i])=="character"){
dset[,i] = as.factor(dset[,i])
}
}
for (i in 1:length(names(dsett))){
if (typeof(dsett[,i])=="character"){
dsett[,i] = as.factor(dsett[,i])
}
}
rf_fit = randomForest(as.formula(frmla),data = dset,mtry=input$rfcmt,maxnodes= input$rfcmn,ntree=input$rfcnt,nodesize = input$rfcns)
rf_pred = predict(rf_fit,data = dset,type = "response")
rf_predt = predict(rf_fit,newdata = dsett,type = "response")
tble = table(rf_pred,dset[,yvar])
tblet = table(rf_predt,dsett[,yvar])
acc = (tble[1,1]+tble[2,2])/sum(tble)
acct = (tblet[1,1]+tblet[2,2])/sum(tblet)
print(paste("Random forest classifer Results"))
print(paste("Train accuracy",round(acc*100,2)))
print(paste("Test accuracy",round(acct*100,2)))
print(varImpPlot(rf_fit))
}
else if (input$selectc =="Boosting_GBM_Classifier"){
xvars = input$xvars
yvar = input$yvar
dset = data.frame(data())
dset[,yvar] = as.factor(dset[,yvar])
dsett = data.frame(tdata())
dsett[,yvar] = as.factor(dsett[,yvar])
frmla = paste(yvar,"~",paste(xvars,collapse = "+"))
for (i in 1:length(names(dset))){
if (typeof(dset[,i])=="character"){
dset[,i] = as.factor(dset[,i])
}
}
for (i in 1:length(names(dsett))){
if (typeof(dsett[,i])=="character"){
dsett[,i] = as.factor(dsett[,i])
}
}
gbm_fit = gbm(as.formula(frmla),data = dset,n.trees = input$btcnt,shrinkage = input$btcsg,interaction.depth = input$btcid,
n.minobsinnode = input$btcid ,distribution = input$btcdu)
gbm_pred = predict(gbm_fit,data = dset,n.trees= input$btcnt,type = "response")
gbm_predt = predict(gbm_fit,newdata = dsett,n.trees= input$btcnt,type = "response")
tble = table(gbm_pred,dset[,yvar])
acc = (tble[1,1]+tble[2,2])/sum(tble)
tblet = table(gbm_predt,dsett[,yvar])
acct = (tblet[1,1]+tblet[2,2])/sum(tblet)
print(paste("Boosting classifer Results"))
print(paste("Train accuracy",round(acc*100,2)))
print(paste("Test accuracy",round(acct*100,2)))
}
else if (input$selectc =="Decision_Tree_Classifier"){
xvars = input$xvars
yvar = input$yvar
dset = data.frame(data())
dset[,yvar] = as.factor(dset[,yvar])
dsett = data.frame(tdata())
dsett[,yvar] = as.factor(dsett[,yvar])
frmla = paste(yvar,"~",paste(xvars,collapse = "+"))
for (i in 1:length(names(dset))){
if (typeof(dset[,i])=="character"){
dset[,i] = as.factor(dset[,i])
}
}
for (i in 1:length(names(dsett))){
if (typeof(dsett[,i])=="character"){
dsett[,i] = as.factor(dsett[,i])
}
}
tr_fit = rpart(as.formula(frmla),data = dset,method = "class",maxdepth=input$trcnt,minsplit = input$trcms, minbucket = input$trcmb)
tr_pred = predict(tr_fit,data = dset,type = "class")
tr_predt = predict(tr_fit,newdata = dsett,type = "class")
tble = table(tr_pred,dset[,yvar])
acc = (tble[1,1]+tble[2,2])/sum(tble)
tblet = table(tr_predt,dsett[,yvar])
acct = (tblet[1,1]+tblet[2,2])/sum(tblet)
print(paste("Decision Tree classifer Results"))
print(paste("Train accuracy",round(acc*100,2)))
print(paste("Test accuracy",round(acct*100,2)))
print(paste("Model summary"))
print(summary(tr_fit))
}
else if (input$selectc =="SVM_Classifier" & input$svckt == "linear"){
xvars = input$xvars
yvar = input$yvar
dset = data.frame(data())
dset[,yvar] = as.factor(dset[,yvar])
dsett = data.frame(tdata())
dsett[,yvar] = as.factor(dsett[,yvar])
for (i in 1:length(names(dset))){
if (typeof(dset[,i])=="character"){
dset[,i] = as.factor(dset[,i])
}
}
for (i in 1:length(names(dsett))){
if (typeof(dsett[,i])=="character"){
dsett[,i] = as.factor(dsett[,i])
}
}
frmla = paste(yvar,"~",paste(xvars,collapse = "+"))
svm_fit = svm(as.formula(frmla),data = dset,kernel="linear",cost = input$svccs,scale = TRUE)
svm_pred = predict(svm_fit,data = dset,type = "response")
svm_predt = predict(svm_fit,newdata = dsett,type = "response")
tble = table(svm_pred,dset[,yvar])
acc = (tble[1,1]+tble[2,2])/sum(tble)
tblet = table(svm_predt,dsett[,yvar])
acct = (tblet[1,1]+tblet[2,2])/sum(tblet)
print(paste("SVM Linear classifer Results"))
print(paste("Train accuracy",round(acc*100,2)))
print(paste("Test accuracy",round(acct*100,2)))
}
else if (input$selectc =="SVM_Classifier" & input$svckt == "poly"){
xvars = input$xvars
yvar = input$yvar
dset = data.frame(data())
dset[,yvar] = as.factor(dset[,yvar])
dsett = data.frame(tdata())
dsett[,yvar] = as.factor(dsett[,yvar])
for (i in 1:length(names(dset))){
if (typeof(dset[,i])=="character"){
dset[,i] = as.factor(dset[,i])
}
}
for (i in 1:length(names(dsett))){
if (typeof(dsett[,i])=="character"){
dsett[,i] = as.factor(dsett[,i])
}
}
frmla = paste(yvar,"~",paste(xvars,collapse = "+"))
svm_fit = svm(as.formula(frmla),data = dset,kernel="poly",cost = input$svccs,degree = input$svcpl,scale = TRUE)
svm_pred = predict(svm_fit,data = dset,type = "response")
svm_predt = predict(svm_fit,newdata = dsett,type = "response")
tble = table(svm_pred,dset[,yvar])
acc = (tble[1,1]+tble[2,2])/sum(tble)
tblet = table(svm_predt,dsett[,yvar])
acct = (tblet[1,1]+tblet[2,2])/sum(tblet)
print(paste("SVM Polynomical Kernel classifer Results"))
print(paste("Train accuracy",round(acc*100,2)))
print(paste("Test accuracy",round(acct*100,2)))
}
else if (input$selectc =="SVM_Classifier" & input$svckt == "radial"){
xvars = input$xvars
yvar = input$yvar
dset = data.frame(data())
dset[,yvar] = as.factor(dset[,yvar])
dsett = data.frame(tdata())
dsett[,yvar] = as.factor(dsett[,yvar])
for (i in 1:length(names(dset))){
if (typeof(dset[,i])=="character"){
dset[,i] = as.factor(dset[,i])
}
}
for (i in 1:length(names(dsett))){
if (typeof(dsett[,i])=="character"){
dsett[,i] = as.factor(dsett[,i])
}
}
frmla = paste(yvar,"~",paste(xvars,collapse = "+"))
svm_fit = svm(as.formula(frmla),data = dset,kernel="radial",cost = input$svccs,gamma =  input$svcgm,scale = TRUE)
svm_pred = predict(svm_fit,data = dset,type = "response")
svm_predt = predict(svm_fit,newdata = dsett,type = "response")
tble = table(svm_pred,dset[,yvar])
acc = (tble[1,1]+tble[2,2])/sum(tble)
tblet = table(svm_predt,dsett[,yvar])
acct = (tblet[1,1]+tblet[2,2])/sum(tblet)
print(paste("SVM RBF kernel classifer Results"))
print(paste("Train accuracy",round(acc*100,2)))
print(paste("Test accuracy",round(acct*100,2)))
}
else if (input$selectc =="Naive_Bayes"){
xvars = input$xvars
yvar = input$yvar
dset = data.frame(data())
dset[,yvar] = as.factor(dset[,yvar])
dsett = data.frame(tdata())
dsett[,yvar] = as.factor(dsett[,yvar])
for (i in 1:length(names(dset))){
if (typeof(dset[,i])=="character"){
dset[,i] = as.factor(dset[,i])
}
}
for (i in 1:length(names(dsett))){
if (typeof(dsett[,i])=="character"){
dsett[,i] = as.factor(dsett[,i])
}
}
frmla = paste(yvar,"~",paste(xvars,collapse = "+"))
nb_fit = naiveBayes(as.formula(frmla),data = dset,laplace = input$nbls,type = "class")
rf_pred = predict(nb_fit,data = dset,type = "response")
rf_predt = predict(nb_fit,newdata = dsett,type = "response")
tble = table(rf_pred,dset[,yvar])
acc = (tble[1,1]+tble[2,2])/sum(tble)
tblet = table(svm_predt,dsett[,yvar])
acct = (tblet[1,1]+tblet[2,2])/sum(tblet)
print(paste("Naive Bayes Results"))
print(paste("Train accuracy",round(acc*100,2)))
print(paste("Test accuracy",round(acct*100,2)))
}
})
output$accrcy <- renderPrint({
STextinputC()
})
STextinputR <- eventReactive(input$actionr, {
if (input$selectr =="Random_Forest_Regressor"){
xvars = input$xvars
yvar = input$yvar
dset = data.frame(data())
dsett = data.frame(tdata())
for (i in 1:length(names(dset))){
if (typeof(dset[,i])=="character"){
dset[,i] = as.factor(dset[,i])
}
}
for (i in 1:length(names(dsett))){
if (typeof(dsett[,i])=="character"){
dsett[,i] = as.factor(dsett[,i])
}
}
frmla = paste(yvar,"~",paste(xvars,collapse = "+"))
rf_fit = randomForest(as.formula(frmla),data = dset,mtry=input$rfrmt,maxnodes= input$rfrmn,ntree=input$rfrnt,nodesize = input$rfrns)
rf_pred = predict(rf_fit,data = dset)
rf_predt = predict(rf_fit,newdata = dsett)
R2 <- 1 - (sum((dset[,yvar]-rf_pred )^2)/sum((dset[,yvar]-mean(dset[,yvar]))^2))
R2T <- 1 - (sum((dsett[,yvar]-rf_predt )^2)/sum((dsett[,yvar]-mean(dsett[,yvar]))^2))
print(paste("Random forest Regressor Results"))
print(paste("Train Adj R-squared",round(R2*100,2)))
print(paste("Test Adj R-squared",round(R2T*100,2)))
print(varImpPlot(rf_fit))
}
else if (input$selectr =="Decision_Tree_Regressor"){
xvars = input$xvars
yvar = input$yvar
dset = data.frame(data())
dsett = data.frame(tdata())
for (i in 1:length(names(dset))){
if (typeof(dset[,i])=="character"){
dset[,i] = as.factor(dset[,i])
}
}
for (i in 1:length(names(dsett))){
if (typeof(dsett[,i])=="character"){
dsett[,i] = as.factor(dsett[,i])
}
}
frmla = paste(yvar,"~",paste(xvars,collapse = "+"))
tr_fit = rpart(as.formula(frmla),data = dset,method = "anova",maxdepth=input$trrnt,minsplit = input$trrms, minbucket = input$trrmb)
tr_pred = predict(tr_fit,data = dset)
tr_predt = predict(tr_fit,newdata = dsett)
R2 <- 1 - (sum((dset[,yvar]-tr_pred )^2)/sum((dset[,yvar]-mean(dset[,yvar]))^2))
R2T <- 1 - (sum((dsett[,yvar]-tr_predt )^2)/sum((dsett[,yvar]-mean(dsett[,yvar]))^2))
print(paste("Decision Tree Regressor Results"))
print(paste("Train Adj R-squared",round(R2*100,2)))
print(paste("Test Adj R-squared",round(R2T*100,2)))
}
else if (input$selectr =="Linear_Regression"){
xvars = input$xvars
yvar = input$yvar
dset = data.frame(data())
dsett = data.frame(tdata())
for (i in 1:length(xvars)){
if (typeof(dset[,xvars[i]])=="character"){
dset[,xvars[i]] = as.factor(dset[,xvars[i]])
}
}
for (i in 1:length(names(dsett))){
if (typeof(dsett[,i])=="character"){
dsett[,i] = as.factor(dsett[,i])
}
}
frmla = paste(yvar,"~",paste(xvars,collapse = "+"))
lnr_fit = lm(as.formula(frmla),data = dset)
rf_pred = predict(lnr_fit,data = dset)
rf_pred = predict(lnr_fit,newdata = dsett)
R2 <- 1 - (sum((dset[,yvar]-rf_pred )^2)/sum((dset[,yvar]-mean(dset[,yvar]))^2))
R2T <- 1 - (sum((dsett[,yvar]-rf_pred )^2)/sum((dsett[,yvar]-mean(dsett[,yvar]))^2))
print(paste("Linear Regression Results"))
print(paste("Train Adj R-squared",round(R2*100,2)))
print(paste("Test Adj R-squared",round(R2T*100,2)))
print(paste("Model summary"))
print(summary(lnr_fit))
}
else if (input$selectr =="SVM_Regressor" & input$svrkt == "linear"){
xvars = input$xvars
yvar = input$yvar
dset = data.frame(data())
dsett = data.frame(tdata())
for (i in 1:length(names(dset))){
if (typeof(dset[,i])=="character"){
dset[,i] = as.factor(dset[,i])
}
}
for (i in 1:length(names(dsett))){
if (typeof(dsett[,i])=="character"){
dsett[,i] = as.factor(dsett[,i])
}
}
frmla = paste(yvar,"~",paste(xvars,collapse = "+"))
svm_fit = svm(as.formula(frmla),data = dset,kernel="linear",cost = input$svrcs,scale = TRUE)
svm_pred = predict(svm_fit,data = dset)
svm_predt = predict(svm_fit,newdata = dsett)
R2 <- 1 - (sum((dset[,yvar]-svm_pred )^2)/sum((dset[,yvar]-mean(dset[,yvar]))^2))
R2T <- 1 - (sum((dsett[,yvar]-svm_predt )^2)/sum((dsett[,yvar]-mean(dsett[,yvar]))^2))
print(paste("SVM Regressor with Linear Kernel Results"))
print(paste("Train Adj R-squared",round(R2*100,2)))
print(paste("Test Adj R-squared",round(R2T*100,2)))
}
else if (input$selectr =="SVM_Regressor" & input$svrkt == "poly"){
xvars = input$xvars
yvar = input$yvar
dset = data.frame(data())
dsett = data.frame(tdata())
for (i in 1:length(names(dset))){
if (typeof(dset[,i])=="character"){
dset[,i] = as.factor(dset[,i])
}
}
for (i in 1:length(names(dsett))){
if (typeof(dsett[,i])=="character"){
dsett[,i] = as.factor(dsett[,i])
}
}
frmla = paste(yvar,"~",paste(xvars,collapse = "+"))
svm_fit = svm(as.formula(frmla),data = dset,kernel="poly",cost = input$svrcs,degree = input$svrpl,scale = TRUE)
svm_pred = predict(svm_fit,data = dset)
svm_predt = predict(svm_fit,newdata = dsett)
R2 <- 1 - (sum((dset[,yvar]-svm_pred )^2)/sum((dset[,yvar]-mean(dset[,yvar]))^2))
R2T <- 1 - (sum((dsett[,yvar]-svm_predt )^2)/sum((dsett[,yvar]-mean(dsett[,yvar]))^2))
print(paste("SVM Regressor with Polynomial Kernel Results"))
print(paste("Train Adj R-squared",round(R2*100,2)))
print(paste("Test Adj R-squared",round(R2T*100,2)))
}
else if (input$selectr =="SVM_Regressor" & input$svrkt == "radial"){
xvars = input$xvars
yvar = input$yvar
dset = data.frame(data())
dsett = data.frame(tdata())
for (i in 1:length(names(dset))){
if (typeof(dset[,i])=="character"){
dset[,i] = as.factor(dset[,i])
}
}
for (i in 1:length(names(dsett))){
if (typeof(dsett[,i])=="character"){
dsett[,i] = as.factor(dsett[,i])
}
}
frmla = paste(yvar,"~",paste(xvars,collapse = "+"))
svm_fit = svm(as.formula(frmla),data = dset,kernel="radial",cost = input$svrcs,gamma =  input$svrgm,scale = TRUE)
svm_pred = predict(svm_fit,data = dset)
svm_predt = predict(svm_fit,newdata = dsett)
R2 <- 1 - (sum((dset[,yvar]-svm_pred )^2)/sum((dset[,yvar]-mean(dset[,yvar]))^2))
R2T <- 1 - (sum((dsett[,yvar]-svm_predt )^2)/sum((dsett[,yvar]-mean(dsett[,yvar]))^2))
print(paste("SVM Regressor with RBF Kernel Results"))
print(paste("Train Adj R-squared",round(R2*100,2)))
print(paste("Test Adj R-squared",round(R2T*100,2)))
}
})
output$accrcyr <- renderPrint({
STextinputR()
})
}
shinyApp(ui,server)
